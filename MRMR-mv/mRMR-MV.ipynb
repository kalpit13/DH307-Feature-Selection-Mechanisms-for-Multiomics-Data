{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sample      _PATIENT  OS.time\n",
      "0    TCGA-04-1331-01  TCGA-04-1331   1336.0\n",
      "1    TCGA-04-1332-01  TCGA-04-1332   1247.0\n",
      "2    TCGA-04-1335-01  TCGA-04-1335     55.0\n",
      "3    TCGA-04-1336-01  TCGA-04-1336   1495.0\n",
      "4    TCGA-04-1337-01  TCGA-04-1337     61.0\n",
      "..               ...           ...      ...\n",
      "599  TCGA-61-2614-01  TCGA-61-2614    262.0\n",
      "600  TCGA-OY-A56P-01  TCGA-OY-A56P   1207.0\n",
      "601  TCGA-OY-A56Q-01  TCGA-OY-A56Q    576.0\n",
      "602  TCGA-VG-A8LO-01  TCGA-VG-A8LO     24.0\n",
      "603  TCGA-WR-A838-01  TCGA-WR-A838    304.0\n",
      "\n",
      "[602 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path_survial_data = 'Dataset/survival-OV_survival.txt'\n",
    "\n",
    "# Define column names based on your data\n",
    "columns_survival = [\"sample\", \"_PATIENT\", \"OS.time\"]\n",
    "\n",
    "# Read the data from the file into a Pandas DataFrame\n",
    "df_survival = pd.read_csv(file_path_survial_data, delimiter=r'\\s+', header=0, na_values=[\"\", \" \", \"Redacted\"])\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "df_survival = df_survival[columns_survival]\n",
    "df_survival = df_survival.dropna()\n",
    "\n",
    "print(df_survival)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID vital_status\n",
      "10   TCGA-04-1331-01     DECEASED\n",
      "11   TCGA-04-1332-01     DECEASED\n",
      "12   TCGA-04-1335-01     DECEASED\n",
      "13   TCGA-04-1336-01       LIVING\n",
      "14   TCGA-04-1337-01     DECEASED\n",
      "..               ...          ...\n",
      "615  TCGA-61-2614-01     DECEASED\n",
      "626  TCGA-OY-A56P-01       LIVING\n",
      "627  TCGA-OY-A56Q-01       LIVING\n",
      "628  TCGA-VG-A8LO-01     DECEASED\n",
      "629  TCGA-WR-A838-01     DECEASED\n",
      "\n",
      "[605 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path_vital = 'Dataset/TCGA.OV.sampleMap-OV_clinicalMatrix'\n",
    "\n",
    "# Read the data from the file into a Pandas DataFrame\n",
    "df_vital = pd.read_csv(file_path_vital, sep='\\t', header=0, na_values=[\"\", \" \", \"Redacted\"])\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "df_vital = df_vital[[\"sampleID\", \"vital_status\"]]\n",
    "df_vital = df_vital.dropna()\n",
    "\n",
    "print(df_vital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sample      _PATIENT  OS.time         sampleID vital_status  \\\n",
      "0    TCGA-04-1331-01  TCGA-04-1331   1336.0  TCGA-04-1331-01     DECEASED   \n",
      "1    TCGA-04-1332-01  TCGA-04-1332   1247.0  TCGA-04-1332-01     DECEASED   \n",
      "2    TCGA-04-1335-01  TCGA-04-1335     55.0  TCGA-04-1335-01     DECEASED   \n",
      "3    TCGA-04-1336-01  TCGA-04-1336   1495.0  TCGA-04-1336-01       LIVING   \n",
      "4    TCGA-04-1337-01  TCGA-04-1337     61.0  TCGA-04-1337-01     DECEASED   \n",
      "..               ...           ...      ...              ...          ...   \n",
      "597  TCGA-61-2614-01  TCGA-61-2614    262.0  TCGA-61-2614-01     DECEASED   \n",
      "598  TCGA-OY-A56P-01  TCGA-OY-A56P   1207.0  TCGA-OY-A56P-01       LIVING   \n",
      "599  TCGA-OY-A56Q-01  TCGA-OY-A56Q    576.0  TCGA-OY-A56Q-01       LIVING   \n",
      "600  TCGA-VG-A8LO-01  TCGA-VG-A8LO     24.0  TCGA-VG-A8LO-01     DECEASED   \n",
      "601  TCGA-WR-A838-01  TCGA-WR-A838    304.0  TCGA-WR-A838-01     DECEASED   \n",
      "\n",
      "     cancer_status  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                0  \n",
      "4                1  \n",
      "..             ...  \n",
      "597              1  \n",
      "598              0  \n",
      "599              1  \n",
      "600              1  \n",
      "601              1  \n",
      "\n",
      "[602 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_survival, df_vital, left_on='sample', right_on='sampleID', how='inner')\n",
    "df_merged['cancer_status'] = ((df_merged['OS.time'] < 1095) | (df_merged['vital_status'] == 'DECEASED')).astype(int)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID      _PATIENT  cancer_status\n",
      "0    TCGA-04-1331-01  TCGA-04-1331              1\n",
      "1    TCGA-04-1332-01  TCGA-04-1332              1\n",
      "2    TCGA-04-1335-01  TCGA-04-1335              1\n",
      "3    TCGA-04-1336-01  TCGA-04-1336              0\n",
      "4    TCGA-04-1337-01  TCGA-04-1337              1\n",
      "..               ...           ...            ...\n",
      "597  TCGA-61-2614-01  TCGA-61-2614              1\n",
      "598  TCGA-OY-A56P-01  TCGA-OY-A56P              0\n",
      "599  TCGA-OY-A56Q-01  TCGA-OY-A56Q              1\n",
      "600  TCGA-VG-A8LO-01  TCGA-VG-A8LO              1\n",
      "601  TCGA-WR-A838-01  TCGA-WR-A838              1\n",
      "\n",
      "[602 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_class = df_merged[['sample', '_PATIENT', 'cancer_status']]\n",
    "df_class = df_class.rename(columns={'sample': 'sampleID'})\n",
    "print(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_status\n",
      "1    503\n",
      "0     99\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_class['cancer_status'].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID  ARHGEF10L     HIF3A     RNF17     RNF10     RNF11  \\\n",
      "0    TCGA-61-1910-01  -0.262892 -2.276126 -0.531035  0.657528 -0.865078   \n",
      "1    TCGA-61-1728-01  -0.543692  1.810774 -0.531035  0.071628 -0.181678   \n",
      "2    TCGA-09-1666-01  -1.668892  0.123074 -0.531035 -0.753772  0.343322   \n",
      "3    TCGA-24-1469-01  -1.281392  4.097674 -0.531035 -0.333972 -0.507178   \n",
      "4    TCGA-04-1348-01  -1.144492  4.363674 -0.531035  0.358628 -0.729078   \n",
      "..               ...        ...       ...       ...       ...       ...   \n",
      "303  TCGA-25-2404-01  -0.650692  1.622274 -0.531035  0.275528 -0.180578   \n",
      "304  TCGA-61-2095-01   0.385408  4.484274  0.290565  0.115528 -0.228178   \n",
      "305  TCGA-29-1702-01  -1.699992  5.387374 -0.531035 -0.670972  0.308122   \n",
      "306  TCGA-24-1417-01  -1.256792  3.476574 -0.531035  0.012128  0.070622   \n",
      "307  TCGA-57-1585-01   0.229008  3.444374 -0.531035 -0.139572 -0.144078   \n",
      "\n",
      "       RNF13   GTF2IP1      REM1     MTVR2  ...     TULP2     NPY5R     GNGT2  \\\n",
      "0   -1.81391  0.379606  0.150754 -0.423399  ... -0.748878 -1.587117 -2.510633   \n",
      "1   -1.09901  0.578406  1.095354  0.649601  ... -0.397378 -1.587117 -0.789233   \n",
      "2   -0.54061  1.126406  0.628754 -0.423399  ... -0.748878 -1.587117 -0.535433   \n",
      "3   -1.12581  0.429606  2.185354  1.435201  ... -0.748878 -1.127517  0.848167   \n",
      "4    0.64369  0.042406  1.447654  1.103801  ... -0.127978 -0.966217  0.660767   \n",
      "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
      "303 -0.93931  0.450306  2.102254  0.607901  ...  0.877622 -1.587117 -0.446933   \n",
      "304 -0.69371  0.409606  1.497654  0.172701  ...  0.267722 -1.587117  0.200967   \n",
      "305 -1.19611  0.403006 -0.047946 -0.423399  ...  1.930422 -1.587117 -1.437733   \n",
      "306 -0.53051 -0.622794  1.051854  0.320501  ...  1.000222 -1.587117  0.934567   \n",
      "307 -1.13371  0.166006  1.526054  0.615001  ...  1.772922 -0.374517  0.431567   \n",
      "\n",
      "       GNGT1     TULP3      PTRF     BCL6B     GSTK1      SELP      SELS  \n",
      "0    2.58051 -0.527277 -0.508586 -0.731027  1.415705 -3.972533  0.280488  \n",
      "1    2.55101  0.644523 -1.043586 -2.238727  1.213805 -1.461233 -0.685312  \n",
      "2    1.28071  1.105023 -0.235086 -2.067827  1.491605 -2.963433 -0.783512  \n",
      "3    2.14571  1.372723 -0.922586 -0.875027 -0.842195 -3.276933 -0.976412  \n",
      "4    1.89921  0.277323 -0.963686 -1.161227  1.373005 -1.843933 -0.089112  \n",
      "..       ...       ...       ...       ...       ...       ...       ...  \n",
      "303 -0.25009  0.041423  0.363114 -0.749827  0.601505 -0.435733 -0.377312  \n",
      "304 -1.28139  0.357323  0.293714 -1.217727  0.010205  0.495667 -1.487612  \n",
      "305 -0.98839  0.481423 -0.353486 -2.599027 -1.041095 -3.551733 -0.128112  \n",
      "306 -1.28139 -0.191477  0.235914 -0.321627  1.033305  0.349467 -1.142212  \n",
      "307  2.10901 -0.302977  1.084814  0.478273 -0.104495  1.207867 -1.010512  \n",
      "\n",
      "[308 rows x 20531 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path_PANCAN = 'Dataset/TCGA.OV.sampleMap_HiSeqV2_PANCAN'\n",
    "\n",
    "# Read the data from the file into a Pandas DataFrame\n",
    "df_PANCAN = pd.read_csv(file_path_PANCAN, delimiter=r'\\s+', header=0, na_values=[\"\", \" \", \"Redacted\"], index_col=0)\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "df_PANCAN = df_PANCAN.transpose()\n",
    "df_PANCAN = df_PANCAN.reset_index()\n",
    "df_PANCAN = df_PANCAN.rename(columns={'index': 'sampleID'})\n",
    "\n",
    "merged2_df = pd.merge(df_PANCAN, df_class, left_on='sampleID', right_on='sampleID', how='inner')\n",
    "df_PANCAN = merged2_df[df_PANCAN.columns]\n",
    "df_PANCAN = df_PANCAN.dropna()\n",
    "print(df_PANCAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID  cg00000292  cg00002426  cg00003994  cg00005847  \\\n",
      "2    TCGA-13-1819-02      0.7734      0.7666      0.0284      0.1780   \n",
      "3    TCGA-31-1953-01      0.7804      0.0808      0.0303      0.6370   \n",
      "4    TCGA-13-1819-01      0.8053      0.3654      0.0438      0.5863   \n",
      "5    TCGA-25-2392-01      0.8874      0.2355      0.0418      0.8103   \n",
      "7    TCGA-24-1552-01      0.8990      0.0202      0.0235      0.0579   \n",
      "..               ...         ...         ...         ...         ...   \n",
      "585  TCGA-24-1545-01      0.8506      0.2008      0.0182      0.2712   \n",
      "586  TCGA-10-0935-01      0.8021      0.0380      0.6720      0.4855   \n",
      "587  TCGA-04-1638-01      0.6975      0.0258      0.0453      0.9007   \n",
      "588  TCGA-23-1118-01      0.9012      0.0863      0.0363      0.5696   \n",
      "589  TCGA-36-2547-01      0.8258      0.1884      0.0450      0.6160   \n",
      "\n",
      "     cg00008493  cg00008713  cg00009407  cg00010193  cg00011459  ...  \\\n",
      "2        0.9898      0.0105      0.0095      0.6027      0.9542  ...   \n",
      "3        0.9825      0.0055      0.0124      0.8040      0.9534  ...   \n",
      "4        0.9879      0.0108      0.0139      0.6061      0.9458  ...   \n",
      "5        0.9907      0.0119      0.0111      0.6391      0.9433  ...   \n",
      "7        0.9897      0.0128      0.0101      0.5243      0.9400  ...   \n",
      "..          ...         ...         ...         ...         ...  ...   \n",
      "585      0.9888      0.0110      0.0076      0.5895      0.9415  ...   \n",
      "586      0.9826      0.0126      0.0148      0.5987      0.8595  ...   \n",
      "587      0.9867      0.0110      0.0090      0.6256      0.9040  ...   \n",
      "588      0.9849      0.0121      0.0257      0.5985      0.9373  ...   \n",
      "589      0.9833      0.0168      0.0106      0.5832      0.9717  ...   \n",
      "\n",
      "     cg27650434  cg27651218  cg27652350  cg27654142  cg27655905  cg27657283  \\\n",
      "2        0.0238      0.9837      0.5255      0.0196      0.0211      0.0370   \n",
      "3        0.0195      0.9896      0.9161      0.0149      0.0167      0.0163   \n",
      "4        0.0127      0.9710      0.8969      0.0236      0.0169      0.0371   \n",
      "5        0.0125      0.9798      0.8417      0.0135      0.0257      0.0241   \n",
      "7        0.0090      0.9533      0.9688      0.0144      0.0262      0.0158   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "585      0.0305      0.9387      0.7867      0.0375      0.0239      0.0188   \n",
      "586      0.0156      0.8940      0.9691      0.0201      0.0422      0.0270   \n",
      "587      0.0079      0.9703      0.9543      0.0090      0.0181      0.0211   \n",
      "588      0.0218      0.9434      0.8794      0.0192      0.0321      0.0205   \n",
      "589      0.0155      0.7472      0.9243      0.0183      0.0292      0.0278   \n",
      "\n",
      "     cg27661264  cg27662379  cg27662877  cg27665659  \n",
      "2        0.3767      0.0100      0.0223      0.0125  \n",
      "3        0.1703      0.0131      0.0196      0.0223  \n",
      "4        0.3831      0.0093      0.0244      0.0134  \n",
      "5        0.1493      0.0082      0.0179      0.0173  \n",
      "7        0.3143      0.0112      0.0202      0.0150  \n",
      "..          ...         ...         ...         ...  \n",
      "585      0.1648      0.0116      0.0183      0.0235  \n",
      "586      0.0200      0.0146      0.0228      0.0104  \n",
      "587      0.0452      0.0071      0.0115      0.0095  \n",
      "588      0.4857      0.0124      0.0288      0.0197  \n",
      "589      0.2460      0.0108      0.0212      0.0293  \n",
      "\n",
      "[413 rows x 23669 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path_HumanMethylation27 = 'Dataset/TCGA.OV.sampleMap_HumanMethylation27'\n",
    "\n",
    "# Read the data from the file into a Pandas DataFrame\n",
    "df_HumanMethylation27 = pd.read_csv(file_path_HumanMethylation27, delimiter=r'\\s+', header=0, na_values=[\"\", \" \", \"Redacted\"], index_col=0)\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "df_HumanMethylation27 = df_HumanMethylation27.transpose()\n",
    "df_HumanMethylation27 = df_HumanMethylation27.reset_index()\n",
    "df_HumanMethylation27 = df_HumanMethylation27.rename(columns={'index': 'sampleID'})\n",
    "merged1_df = pd.merge(df_HumanMethylation27, df_class, left_on='sampleID', right_on='sampleID', how='inner')\n",
    "df_HumanMethylation27 = merged1_df[df_HumanMethylation27.columns]\n",
    "# Assuming df_HumanMethylation27 is your DataFrame\n",
    "threshold = 5\n",
    "\n",
    "# Drop columns with more than 10 missing values\n",
    "df_HumanMethylation27 = df_HumanMethylation27.dropna(axis=1, thresh=len(df_HumanMethylation27) - threshold)\n",
    "df_HumanMethylation27 = df_HumanMethylation27.dropna()\n",
    "print(df_HumanMethylation27)\n",
    "# print(df_HumanMethylation27.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID  ACAP3  ACTRT2   AGRN  ANKRD65  ATAD3A  ATAD3B  ATAD3C  \\\n",
      "0    TCGA-04-1331-01  0.080   0.080  0.080    0.080   0.080   0.080   0.080   \n",
      "1    TCGA-04-1332-01 -0.807  -0.807 -0.807   -0.807  -0.807  -0.807  -0.807   \n",
      "2    TCGA-04-1335-01  0.101   0.101  0.101    0.101   0.101   0.101   0.101   \n",
      "3    TCGA-04-1336-01  0.021   0.021  0.021    0.021   0.021   0.021   0.021   \n",
      "4    TCGA-04-1337-01 -0.999  -0.999 -0.999   -0.999  -0.999  -0.999  -0.999   \n",
      "..               ...    ...     ...    ...      ...     ...     ...     ...   \n",
      "561  TCGA-61-2613-01 -0.134  -0.134 -0.134   -0.134  -0.134  -0.134  -0.134   \n",
      "562  TCGA-61-2614-01  0.224   0.224  0.224    0.224   0.224   0.224   0.224   \n",
      "563  TCGA-OY-A56P-01  0.000   0.000  0.000    0.000   0.000   0.000   0.000   \n",
      "564  TCGA-OY-A56Q-01  0.137   0.137  0.137    0.137   0.137   0.137   0.137   \n",
      "565  TCGA-VG-A8LO-01 -0.176  -0.176 -0.176   -0.176  -0.176  -0.176  -0.176   \n",
      "\n",
      "     AURKAIP1  B3GALT6  ...  SMIM9  SNORA36A  SNORA56  TMLHE   VBP1  \\\n",
      "0       0.080    0.080  ... -0.256    -0.256   -0.256 -0.256 -0.256   \n",
      "1      -0.807   -0.807  ...  0.673     0.673    0.673  0.673  0.673   \n",
      "2       0.101    0.101  ... -0.336    -0.336   -0.336 -0.336 -0.336   \n",
      "3       0.021    0.021  ...  0.062     0.062    0.062  0.062  0.062   \n",
      "4      -0.999   -0.999  ... -0.082    -0.082   -0.082 -0.082 -0.082   \n",
      "..        ...      ...  ...    ...       ...      ...    ...    ...   \n",
      "561    -0.134   -0.134  ...  0.325     0.325    0.325  0.325  0.325   \n",
      "562     0.224    0.224  ...  0.061     0.061    0.061  0.061  0.061   \n",
      "563     0.000    0.000  ... -0.195    -0.195   -0.195 -0.195 -0.195   \n",
      "564     0.137    0.137  ... -0.675    -0.675   -0.675 -0.675 -0.675   \n",
      "565    -0.176   -0.176  ...  0.065     0.065    0.065  0.065  0.065   \n",
      "\n",
      "     IL9R|ENSG00000124334.12  SPRY3|ENSG00000168939.6  \\\n",
      "0                     -0.256                   -0.256   \n",
      "1                      0.673                    0.673   \n",
      "2                     -0.336                   -0.336   \n",
      "3                      0.062                    0.062   \n",
      "4                     -0.082                   -0.082   \n",
      "..                       ...                      ...   \n",
      "561                    0.325                    0.325   \n",
      "562                    0.061                    0.061   \n",
      "563                   -0.195                   -0.195   \n",
      "564                   -0.675                   -0.675   \n",
      "565                    0.065                    0.065   \n",
      "\n",
      "     VAMP7|ENSG00000124333.10  WASH6P|ENSG00000182484.10  \\\n",
      "0                      -0.256                     -0.256   \n",
      "1                       0.673                      0.673   \n",
      "2                      -0.336                     -0.336   \n",
      "3                       0.062                      0.062   \n",
      "4                      -0.082                     -0.082   \n",
      "..                        ...                        ...   \n",
      "561                     0.325                      0.325   \n",
      "562                     0.061                      0.061   \n",
      "563                    -0.195                     -0.195   \n",
      "564                    -0.675                     -0.675   \n",
      "565                     0.065                      0.065   \n",
      "\n",
      "     WASIR1|ENSG00000185203.7  \n",
      "0                      -0.256  \n",
      "1                       0.673  \n",
      "2                      -0.336  \n",
      "3                       0.062  \n",
      "4                      -0.082  \n",
      "..                        ...  \n",
      "561                     0.325  \n",
      "562                     0.061  \n",
      "563                    -0.195  \n",
      "564                    -0.675  \n",
      "565                     0.065  \n",
      "\n",
      "[566 rows x 24777 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path_Gistic2 = 'Dataset/TCGA.OV.sampleMap_Gistic2_CopyNumber_Gistic2_all_data_by_genes'\n",
    "\n",
    "# Read the data from the file into a Pandas DataFrame\n",
    "df_Gistic2 = pd.read_csv(file_path_Gistic2, delimiter=r'\\s+', header=0, na_values=[\"\", \" \", \"Redacted\"], index_col=0)\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "df_Gistic2 = df_Gistic2.transpose()\n",
    "df_Gistic2 = df_Gistic2.reset_index()\n",
    "df_Gistic2 = df_Gistic2.rename(columns={'index': 'sampleID'})\n",
    "merged1_df = pd.merge(df_Gistic2, df_class, left_on='sampleID', right_on='sampleID', how='inner')\n",
    "df_Gistic2 = merged1_df[df_Gistic2.columns]\n",
    "df_Gistic2 = df_Gistic2.dropna()\n",
    "print(df_Gistic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'sampleID' is the common column in all dataframes\n",
    "\n",
    "# Get the unique 'sampleID' from each dataframe\n",
    "sampleID_Gistic2 = set(df_Gistic2['sampleID'])\n",
    "sampleID_HumanMethylation27 = set(df_HumanMethylation27['sampleID'])\n",
    "sampleID_PANCAN = set(df_PANCAN['sampleID'])\n",
    "sampleID_class = set(df_class['sampleID'])\n",
    "\n",
    "# Find the common 'sampleID' using set intersection\n",
    "common_sampleID = (\n",
    "    sampleID_Gistic2\n",
    "    & sampleID_HumanMethylation27\n",
    "    & sampleID_PANCAN\n",
    "    & sampleID_class\n",
    ")\n",
    "\n",
    "# Create a dataframe with the common 'sampleID'\n",
    "df_common_sampleID = pd.DataFrame({'sampleID': list(common_sampleID)})\n",
    "\n",
    "# Display the resulting dataframe\n",
    "# print(df_common_sampleID)\n",
    "\n",
    "# Get the common 'sampleID' set\n",
    "common_sampleID_set = set(df_common_sampleID['sampleID'])\n",
    "\n",
    "# Filter each dataframe to include only rows with common 'sampleID'\n",
    "df_Gistic2 = df_Gistic2[df_Gistic2['sampleID'].isin(common_sampleID_set)]\n",
    "df_HumanMethylation27 = df_HumanMethylation27[df_HumanMethylation27['sampleID'].isin(common_sampleID_set)]\n",
    "df_PANCAN = df_PANCAN[df_PANCAN['sampleID'].isin(common_sampleID_set)]\n",
    "df_class = df_class[df_class['sampleID'].isin(common_sampleID_set)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def Scaler(df):\n",
    "    # Extract numeric columns (you may need to adjust this based on your dataframe)\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    # Fit and transform the numeric columns\n",
    "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    return df\n",
    "\n",
    "\n",
    "df_Gistic2 = Scaler(df_Gistic2)\n",
    "df_HumanMethylation27 = Scaler(df_HumanMethylation27)\n",
    "df_PANCAN = Scaler(df_PANCAN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def VarianceThreshold(df, threshold = 0.02):\n",
    "    # Save the 'sampleID' column\n",
    "    sampleID_column = df['sampleID']\n",
    "\n",
    "    # Drop the 'sampleID' column before calculating variance\n",
    "    df_without_sampleID = df.drop(columns=['sampleID'])\n",
    "\n",
    "    # Calculate variance for each remaining column\n",
    "    variances = df_without_sampleID.var()\n",
    "\n",
    "    # Filter columns with variance >= threshold\n",
    "    selected_columns = variances[variances >= threshold].index\n",
    "\n",
    "    # Add back the 'sampleID' column to the selected columns\n",
    "    selected_columns = ['sampleID'] + list(selected_columns)\n",
    "\n",
    "    # Create a new DataFrame with selected columns\n",
    "    filtered_df = df[selected_columns]\n",
    "\n",
    "    # Display the resulting DataFrame\n",
    "    return filtered_df\n",
    "    \n",
    "df_Gistic2 = VarianceThreshold(df_Gistic2)\n",
    "df_HumanMethylation27 = VarianceThreshold(df_HumanMethylation27)\n",
    "df_PANCAN = VarianceThreshold(df_PANCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortData(df):\n",
    "    # Sort DataFrame based on 'sampleID'\n",
    "    df_sorted = df.sort_values(by='sampleID')\n",
    "\n",
    "    # Reset the index\n",
    "    df_sorted = df_sorted.reset_index(drop=True)\n",
    "\n",
    "    # Display the sorted and reset DataFrame\n",
    "    return df_sorted\n",
    "\n",
    "df_Gistic2 = sortData(df_Gistic2)\n",
    "df_HumanMethylation27 = sortData(df_HumanMethylation27)\n",
    "df_PANCAN = sortData(df_PANCAN)\n",
    "df_class = sortData(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217, 3155)\n",
      "(217, 5245)\n",
      "(217, 1175)\n"
     ]
    }
   ],
   "source": [
    "th = 0.04\n",
    "df_Gistic21 = VarianceThreshold(df_Gistic2, th)\n",
    "df_HumanMethylation271 = VarianceThreshold(df_HumanMethylation27, th)\n",
    "df_PANCAN1 = VarianceThreshold(df_PANCAN, th)\n",
    "print(df_PANCAN1.shape)\n",
    "print(df_HumanMethylation271.shape)\n",
    "print(df_Gistic21.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_status\n",
      "1    192\n",
      "0     25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_class['cancer_status'].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df_PANCAN1                                 #0\n",
    "df_1 = df_Gistic21                                #1\n",
    "df_2 = df_HumanMethylation271                     #2\n",
    "\n",
    "n0 = df_0.shape[0]\n",
    "n1 = df_1.shape[0]\n",
    "n2 = df_2.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def LassoFeatureSelection(df, target):\n",
    "    # Assuming df_0 is your DataFrame containing features\n",
    "\n",
    "    # Separate the features (X) and the target variable (y) if applicable\n",
    "    X = df.drop(columns=['sampleID'])  # Remove 'target_column' if it exists\n",
    "    y = target  # Replace 'target_column' with your target variable name\n",
    "\n",
    "    # Step 1: Instantiate Lasso Model\n",
    "    lasso = Lasso(alpha=0.001)  # You can adjust the alpha value as needed\n",
    "\n",
    "    # Step 2: Fit Model\n",
    "    lasso.fit(X, y)\n",
    "\n",
    "    # Step 3: Get Feature Importance\n",
    "    feature_importance = np.abs(lasso.coef_)\n",
    "\n",
    "    # Step 4: Select Top Features\n",
    "    num_top_features = 100  # Number of top features to select\n",
    "    top_feature_indices = np.argsort(feature_importance)[::-1][:num_top_features]\n",
    "    top_features = X.columns[top_feature_indices]\n",
    "\n",
    "    # Create a new DataFrame with the top features\n",
    "    df_top_features = df[top_features]\n",
    "\n",
    "    df_top_features = pd.concat([df['sampleID'], df_top_features], axis=1)\n",
    "\n",
    "    # Display the new DataFrame with top features\n",
    "    return df_top_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = LassoFeatureSelection(df_0,df_class['cancer_status'])\n",
    "df_1 = LassoFeatureSelection(df_1,df_class['cancer_status'])\n",
    "df_2 = LassoFeatureSelection(df_2,df_class['cancer_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "201\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_0 is your DataFrame\n",
    "# column_names = df_0.columns\n",
    "\n",
    "# Create a map0 mapping column names to their numbers indexed from 1\n",
    "map0 = {column: (0, index) for index, column in enumerate(df_0.columns)}\n",
    "map1 = {column: (1, index) for index, column in enumerate(df_1.columns)}\n",
    "map2 = {column: (2, index) for index, column in enumerate(df_2.columns)}\n",
    "\n",
    "print(len(map0))\n",
    "print(len(map1))\n",
    "print(len(map2))\n",
    "\n",
    "# Display map0\n",
    "# print(map2)\n",
    "\n",
    "# Assuming map0, map1, map2 are your dictionaries\n",
    "Feature_to_Index = {}\n",
    "\n",
    "# Merge map0, map1, and map2 into mapF\n",
    "Feature_to_Index.update(map2)\n",
    "print(len(Feature_to_Index))\n",
    "Feature_to_Index.update(map1)\n",
    "print(len(Feature_to_Index))\n",
    "Feature_to_Index.update(map0)\n",
    "print(len(Feature_to_Index))\n",
    "\n",
    "# Display mapF\n",
    "\n",
    "# Create the opposite mapping of mapF\n",
    "Index_to_Feature = {value: key for key, value in Feature_to_Index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_index = {column: index for index, column in enumerate(Feature_to_Index.keys())}\n",
    "index_to_column = {index: column for column, index in column_to_index.items()}\n",
    "dfs = {0: df_0, 1: df_1, 2: df_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.04740484 ... 0.07218802 0.09282057 0.04867271]\n",
      " [0.         0.04740484 1.         ... 0.06279655 0.12465636 0.11964636]\n",
      " ...\n",
      " [0.         0.07218802 0.06279655 ... 1.         0.11501993 0.21688761]\n",
      " [0.         0.09282057 0.12465636 ... 0.11501993 1.         0.03982409]\n",
      " [0.         0.04867271 0.11964636 ... 0.21688761 0.03982409 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_ = len(index_to_column)\n",
    "g_Function = np.zeros((n_, n_))\n",
    "\n",
    "for i in range(1,n_):\n",
    "    for j in range(1,n_):\n",
    "        col1 = index_to_column[i]\n",
    "        col2 = index_to_column[j]\n",
    "\n",
    "        add1 = Feature_to_Index[col1]\n",
    "        add2 = Feature_to_Index[col2]\n",
    "\n",
    "        corr_coefficient, p_value = pearsonr(dfs[add1[0]][col1], dfs[add2[0]][col2])\n",
    "        g_Function[i][j] = abs(corr_coefficient)\n",
    "\n",
    "print(g_Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sampleID  cg02600394  cg17987660  cg21634602  cg19682367  \\\n",
      "0    TCGA-04-1348-01    0.434663    0.207875    0.002905    0.550188   \n",
      "1    TCGA-04-1357-01    0.252407    0.217949    0.002783    0.699784   \n",
      "2    TCGA-04-1362-01    0.950481    0.076313    0.007866    0.210095   \n",
      "3    TCGA-04-1364-01    0.686382    0.053419    0.016580    0.009343   \n",
      "4    TCGA-04-1365-01    0.660935    0.025946    0.007382    0.931526   \n",
      "..               ...         ...         ...         ...         ...   \n",
      "212  TCGA-61-2104-01    0.794360    0.236264    0.009561    0.702062   \n",
      "213  TCGA-61-2109-01    0.904402    0.022589    0.015854    0.158141   \n",
      "214  TCGA-61-2110-01    0.853508    0.031746    0.005446    0.877407   \n",
      "215  TCGA-61-2111-01    0.799862    0.219170    0.019121    0.461319   \n",
      "216  TCGA-61-2113-01    0.768226    0.843407    0.014765    0.292583   \n",
      "\n",
      "     cg13754949  cg26177629  cg25094569  cg25195673  cg09542291  ...  \\\n",
      "0      0.307317    0.010408    0.634611    0.132050    0.917344  ...   \n",
      "1      0.185366    0.077315    0.423784    0.442791    0.926739  ...   \n",
      "2      0.263415    0.008709    0.634275    0.110541    0.917450  ...   \n",
      "3      0.063415    0.709643    0.628110    0.002626    0.732292  ...   \n",
      "4      0.053659    0.015293    0.672159    0.795673    0.654175  ...   \n",
      "..          ...         ...         ...         ...         ...  ...   \n",
      "212    0.048780    0.009771    0.309796    0.239465    0.034202  ...   \n",
      "213    0.058537    0.002974    0.005268    0.152057    0.979943  ...   \n",
      "214    0.058537    0.025701    0.002354    0.119920    0.988494  ...   \n",
      "215    0.092683    0.012957    0.343421    0.221708    0.940673  ...   \n",
      "216    0.068293    0.097494    0.853844    0.223959    0.349731  ...   \n",
      "\n",
      "       POU6F2     GSTT1    FAM83F    CD40LG    CALML3      NCR2     DIRC1  \\\n",
      "0    0.266319  0.847376  0.496349  0.647391  0.139931  0.081845  0.110565   \n",
      "1    0.092632  0.868771  0.577508  0.941195  0.000000  0.000000  0.000000   \n",
      "2    0.052828  0.838666  0.679052  0.349750  0.113259  0.000000  0.000000   \n",
      "3    0.726202  0.135658  0.918929  0.000000  0.515306  0.000000  0.000000   \n",
      "4    0.209597  0.810098  0.600190  0.614980  0.105757  0.090515  0.203180   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "212  0.000000  0.879299  0.745462  0.603434  0.145088  0.000000  0.000000   \n",
      "213  0.749395  0.744765  0.645156  0.358137  0.064035  0.230122  0.000000   \n",
      "214  0.000000  0.810098  0.782827  0.490926  0.452967  0.464008  0.000000   \n",
      "215  0.465300  0.739898  0.851325  0.604761  0.000000  0.000000  0.000000   \n",
      "216  0.500070  0.522907  0.239535  0.510275  0.000000  0.000000  0.555407   \n",
      "\n",
      "         NXF2      AGR2     CHRM3  \n",
      "0    0.077187  0.531690  0.434364  \n",
      "1    0.000000  0.460200  0.590364  \n",
      "2    0.156446  0.280510  0.242861  \n",
      "3    0.896565  0.338486  0.655124  \n",
      "4    0.034370  0.466540  0.698993  \n",
      "..        ...       ...       ...  \n",
      "212  0.000000  0.671029  0.296963  \n",
      "213  0.000000  0.000000  0.000000  \n",
      "214  0.000000  0.620258  0.554885  \n",
      "215  0.846059  0.915011  0.203533  \n",
      "216  0.000000  0.708063  0.249833  \n",
      "\n",
      "[217 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_2, df_1, on='sampleID', how='inner')  # Adjust 'how' parameter as needed\n",
    "\n",
    "# Merge df_merged with df_2\n",
    "df_merged = pd.merge(df_merged, df_0, on='sampleID', how='inner')  # Adjust 'how' parameter as needed\n",
    "\n",
    "# Drop the 'ARHGEF38_x' column\n",
    "df_merged.drop(columns=['ARHGEF38_x'], inplace=True)\n",
    "\n",
    "# Rename the 'ARHGEF38_y' column to 'ARHGEF38'\n",
    "df_merged.rename(columns={'ARHGEF38_y': 'ARHGEF38'}, inplace=True)\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.45148487e+01 1.36322311e+00 1.03621262e+01\n",
      " 2.29492911e+00 2.72278903e+00 2.78199440e+00 9.09484520e+00\n",
      " 1.73412082e+01 9.60239867e+00 2.93001277e+00 1.87549364e+01\n",
      " 4.24681245e-01 6.83375880e-01 1.29229457e+01 3.46562479e+00\n",
      " 1.56448505e+01 4.82641879e+00 7.63006913e+00 3.27730568e+00\n",
      " 1.78435600e-01 4.28644559e+00 1.06800423e+01 1.47990797e+00\n",
      " 1.26081981e+01 2.59438520e+00 4.76435878e+00 1.50423756e+00\n",
      " 7.65761998e+00 3.04726257e+00 3.47880812e+00 1.57693503e+01\n",
      " 8.68882459e+00 5.62703626e+00 2.79514900e+00 7.76997390e-01\n",
      " 3.89467230e+00 1.19695264e+00 3.86991330e+00 8.95745501e-01\n",
      " 2.47488705e+00 1.27585671e+00 4.62988984e+00 4.56451063e-01\n",
      " 8.39782618e-01 8.85756607e-01 8.64584335e-01 8.58802972e-01\n",
      " 1.08886945e+00 2.82524459e-01 2.16730126e+00 1.25890530e-01\n",
      " 2.58426615e+00 4.67300007e+00 6.76455332e+00 1.83015074e+00\n",
      " 7.53210525e+00 6.98402958e+00 4.40399867e+00 1.63015803e-01\n",
      " 9.72268226e-01 8.09329050e+00 5.38924635e-02 3.89500246e+00\n",
      " 8.54101087e+00 1.11756984e+00 7.93672217e-01 2.44207644e+00\n",
      " 5.25754228e+00 9.26935044e+00 6.12397904e-01 1.59089100e+00\n",
      " 2.20630151e+00 4.65111681e-01 5.67673081e+00 1.36042232e+00\n",
      " 4.23422869e-01 5.32415504e+00 5.04992391e-01 4.46340114e+00\n",
      " 7.19726881e-01 9.70317492e-01 2.28084205e-01 1.57857704e-02\n",
      " 6.90199838e+00 1.06826446e+00 1.98747933e+00 9.97922706e-01\n",
      " 4.64313463e-01 1.04014482e+00 5.42979775e-03 8.97332514e-02\n",
      " 2.44179486e+00 2.87459378e+00 2.91971114e+00 7.40489539e-01\n",
      " 3.32366419e+00 2.08163785e+00 5.43408659e-01 3.29314265e-01\n",
      " 2.54119748e-02 6.51288224e-01 4.96981635e+00 3.90563013e+00\n",
      " 3.74010747e-02 1.83203844e+00 4.50277152e-01 9.19168913e-01\n",
      " 1.82625162e+00 3.08631134e-01 1.36423271e+00 1.26660482e+00\n",
      " 9.60872640e-01 2.50391853e+00 7.97482878e-01 2.89726832e-03\n",
      " 4.08887062e-01 4.88245244e+00 5.52757532e-01 7.39552691e-01\n",
      " 2.66574182e-01 9.31568058e-01 4.47132340e+00 8.84890277e-01\n",
      " 5.66858187e-01 8.83273692e-02 5.95991819e-01 2.75059999e+00\n",
      " 5.14732818e+00 6.42124172e+00 2.49657404e-02 1.19542370e+00\n",
      " 5.62814521e-01 3.26394657e-01 6.92804599e-01 3.04194675e+00\n",
      " 1.98587359e-01 2.00553784e-02 1.37431708e-01 2.04150021e+00\n",
      " 2.10411822e-01 1.52243061e-04 2.38288057e-01 2.87743415e-01\n",
      " 5.24747382e-01 7.02683477e-02 1.97020776e+00 5.54041070e-01\n",
      " 1.45779442e-01 1.51474094e+00 1.92698422e+00 6.76055079e-01\n",
      " 5.37968869e-01 1.03678102e+00 2.15502401e+00 9.89482337e-02\n",
      " 1.49656603e+00 1.26919528e-01 2.44438957e+00 3.76906348e-01\n",
      " 4.42897891e-01 4.23686339e-01 4.76520120e-01 5.20465401e+00\n",
      " 2.03527974e+00 3.80468952e-01 4.81060925e-03 2.25959035e+00\n",
      " 6.48704065e-01 1.88597746e-01 5.23959983e+00 3.53537656e-02\n",
      " 5.15014196e-01 1.51540472e+00 2.16261386e+00 4.40977935e+00\n",
      " 2.08428232e+00 3.19388298e-01 1.26660482e+00 1.83203844e+00\n",
      " 4.88245244e+00 3.19388298e-01 5.62814521e-01 4.40977935e+00\n",
      " 7.02683477e-02 5.15014196e-01 1.26660482e+00 1.26660482e+00\n",
      " 1.26660482e+00 1.26660482e+00 1.26660482e+00 1.26660482e+00\n",
      " 1.50431744e+00 2.21331580e+00 1.52104874e+00 1.64760807e-01\n",
      " 1.52104874e+00 1.43373756e+00 1.43373756e+00 1.64760807e-01\n",
      " 1.82805418e+01 3.80537882e+00 4.81100227e-01 5.44253097e+00\n",
      " 1.77035263e+00 1.59759159e+01 4.61577258e-02 4.87509308e+00\n",
      " 3.34066634e+00 5.03112329e+00 6.70601385e+00 9.51499898e+00\n",
      " 6.38982732e+00 9.15794940e+00 3.14478486e+00 5.70556464e+00\n",
      " 1.87526436e+00 1.21348389e+00 2.05511918e-01 4.97161100e+00\n",
      " 7.01939192e-01 9.21482307e-01 1.95464826e+00 1.13263862e+01\n",
      " 8.94605793e+00 4.67025040e+00 3.25341092e+00 2.06774275e+00\n",
      " 1.12864480e+00 2.79646521e+00 4.36704125e+00 2.48721912e+00\n",
      " 1.18281376e+00 1.72832228e-02 4.43585434e+00 5.68097759e+00\n",
      " 3.57967229e+00 1.84783524e+00 7.52943029e+00 1.27273490e+00\n",
      " 8.38624898e+00 7.76337502e-01 2.95181512e+00 2.65947822e+00\n",
      " 9.45625374e-01 2.17247434e+00 3.42723678e+00 3.52923259e-01\n",
      " 6.12994544e-01 4.11912435e+00 5.25190851e+00 5.89236714e+00\n",
      " 3.82936026e+00 7.00709124e+00 3.07017916e+00 4.46315533e+00\n",
      " 1.65554984e+00 9.38334091e-01 1.07806193e+01 7.05688214e+00\n",
      " 6.83683756e-01 8.45368094e+00 1.90765016e+00 1.09170520e+00\n",
      " 5.25619259e-01 3.30180215e+00 3.56999217e-03 3.53988963e+00\n",
      " 4.69450338e+00 1.93115974e+00 1.10318775e+00 5.48935418e+00\n",
      " 4.06553012e+00 5.36208017e+00 3.82026786e+00 4.11468994e+00\n",
      " 6.50383365e-01 5.55249564e+00 1.06180849e+01 1.17530922e+00\n",
      " 1.20673370e+00 2.69536723e+00 6.81287465e+00 3.52402226e+00\n",
      " 6.19568584e+00 6.05905636e-02 3.26184209e+00 5.91705344e-01\n",
      " 1.22060042e+00 2.70420718e+00 1.58211663e+00 2.28817703e+00\n",
      " 6.02848389e+00 7.37500163e+00 5.08358824e+00 2.86682442e+00\n",
      " 4.52338926e+00 2.55029090e-01 8.06748804e+00 9.47325842e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "\n",
    "# Calculate Chi-squared score\n",
    "chi2_score, _ = chi2(df_merged.drop(columns=['sampleID']), df_class['cancer_status'])\n",
    "\n",
    "# Calculate F-statistic (F-Stat)\n",
    "f_statistic, _ = f_classif(df_merged.drop(columns=['sampleID']), df_class['cancer_status'])\n",
    "\n",
    "# Calculate Mutual Information (MI)\n",
    "mi_score = mutual_info_classif(df_merged.drop(columns=['sampleID']), df_class['cancer_status'])\n",
    "\n",
    "F_statistic = np.concatenate([np.empty(1), f_statistic])\n",
    "Chi2_score = np.concatenate([np.empty(1), chi2_score])\n",
    "MI_score = np.concatenate([np.empty(1), mi_score])\n",
    "\n",
    "print(F_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MRMR-mv ALGORITHM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Argument(Selected_Features, current_Feature, f_values, g_values, t):\n",
    "    value = 0.0\n",
    "    index = column_to_index[current_Feature]\n",
    "    value += f_values[index]\n",
    "    g_sum = 0.0\n",
    "\n",
    "    for i in Selected_Features:\n",
    "        g_sum += g_values[index][i]\n",
    "\n",
    "    g_sum = g_sum/(1.0*pow(t+1,2))\n",
    "\n",
    "    value -= g_sum\n",
    "    return value\n",
    "\n",
    "def MRMRmv_Implementation(k,f_values,g_values,v,p0,p1,p2):\n",
    "    S = [[] for _ in range(v)]\n",
    "    V = np.array([0, 1, 2])\n",
    "    C = np.random.choice(V, size=k-1, p=[p0, p1, p2])\n",
    "    Selected_Features = []\n",
    "\n",
    "    max_index = np.argmax(f_values)\n",
    "    v1 = Feature_to_Index[index_to_column[max_index]]\n",
    "    Selected_Features.append(max_index)\n",
    "    S[v1[0]].append(v1[1])\n",
    "\n",
    "    for i in range (0,k-1):\n",
    "        view = C[i]\n",
    "\n",
    "        ArgMax = -100000000\n",
    "        Select = -1\n",
    "\n",
    "        for col in dfs[view].columns:\n",
    "            if(col == 'sampleID'): \n",
    "                continue\n",
    "            if column_to_index[col] in Selected_Features:\n",
    "                continue\n",
    "\n",
    "            val = Argument(Selected_Features,col,f_values,g_values,i)\n",
    "\n",
    "            if(val>ArgMax):\n",
    "                ArgMax = val\n",
    "                Select = column_to_index[col]\n",
    "        \n",
    "        if Select==-1:\n",
    "            continue\n",
    "\n",
    "        Selected_Features.append(Select)\n",
    "        v = Feature_to_Index[index_to_column[Select]]\n",
    "        S[v[0]].append(v[1])\n",
    "\n",
    "    return S, Selected_Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, Selected_Features = MRMRmv_Implementation(10,F_statistic, g_Function, 3, 0.33, 0.33, 0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_DF(Selected_Features):\n",
    "    df_selected = df_0[['sampleID']].copy()\n",
    "\n",
    "    for i in Selected_Features:\n",
    "        col = index_to_column[i]\n",
    "        add = Feature_to_Index[col]\n",
    "\n",
    "        df_selected = pd.merge(df_selected, dfs[add[0]][['sampleID', col]], on='sampleID', how='inner')\n",
    "    \n",
    "    return df_selected\n",
    "\n",
    "df_selected = Create_DF(Selected_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9318181818181818\n",
      "Cross-validated accuracy: 0.878655462184874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.93      1.00      0.96        41\n",
      "\n",
      "    accuracy                           0.93        44\n",
      "   macro avg       0.47      0.50      0.48        44\n",
      "weighted avg       0.87      0.93      0.90        44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/its_priyans/Desktop/Academic Zone/DH 307 RnD Project/Implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/its_priyans/Desktop/Academic Zone/DH 307 RnD Project/Implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/its_priyans/Desktop/Academic Zone/DH 307 RnD Project/Implementation/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming X contains the features and y contains the target variable\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_selected.drop(columns=['sampleID']), df_class['cancer_status'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Initialize Stratified K-Folds cross-validator\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy on test set:\", log_reg.score(X_test, y_test))\n",
    "print(\"Cross-validated accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_status\n",
      "1    192\n",
      "0     25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'series' is your Pandas Series\n",
    "value_counts = df_class['cancer_status'].value_counts()\n",
    "print(value_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
